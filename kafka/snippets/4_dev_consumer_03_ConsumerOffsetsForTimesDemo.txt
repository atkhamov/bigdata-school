package kz.beeline.bigdata.amadraimov.KafkaProducer;

import org.apache.kafka.clients.consumer.*;
import org.apache.kafka.common.PartitionInfo;
import org.apache.kafka.common.TopicPartition;
import org.apache.kafka.common.message.ElectPreferredLeadersRequestData;
import org.apache.kafka.common.serialization.StringDeserializer;

import java.sql.Timestamp;
import java.text.ParseException;
import java.text.SimpleDateFormat;
import java.time.Duration;
import java.util.*;

public class ConsumerOffsetsForTimesDemo {
    public static void main(String[] args) throws ParseException {

        String bootstrapServers = "127.0.0.1:9092";
        String groupId = "idea-01";
        String topic = "test_01";
        int partition = 0;
        TopicPartition topicPartition = new TopicPartition(topic, partition);

        // create configs
        Properties properties = new Properties();
        properties.setProperty(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, bootstrapServers);
        properties.setProperty(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());
        properties.setProperty(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());
        properties.setProperty(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG, "earliest");

        // create consumer
        KafkaConsumer<String, String> consumer = new KafkaConsumer<String, String>(properties);

        // search for offset
        long timestamp = new SimpleDateFormat("yyyy-MM-dd HH:mm:ss.SSS")
                .parse("2019-09-20 10:00:00.000").getTime();

        // create partition,timestamp map
        Map<TopicPartition, Long> query = new HashMap<>();
        // put partitions and timestamps to map
        query.put(topicPartition, timestamp);
        Map<TopicPartition, OffsetAndTimestamp> result  = consumer.offsetsForTimes(query);

        // assign
            consumer.assign(Arrays.asList(topicPartition));

        // seek
        long offset = 1400;
        for (Map.Entry<TopicPartition, OffsetAndTimestamp> entry : result.entrySet()) {
            consumer.seek(entry.getKey(), entry.getValue().offset());
        }

        // poll data
        int readCount = 10;
        boolean read = true;
        while (read){
            ConsumerRecords<String, String> records = consumer.poll(Duration.ofMillis(100));

            for (ConsumerRecord<String, String> record : records){
                readCount--;
                Date date = new Date(new Timestamp(record.timestamp()).getTime());
                System.out.printf("%s,topic %s,part %s,offset %s,key %s,value %s%n", date.toString(),
                        record.topic(), record.partition(), record.offset(), record.key(), record.value());
                if (readCount == 0) {
                    read = false;
                    break;
                }
            }
        }
    }
}
